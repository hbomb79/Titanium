class Lexer {
    static = {
        escapeChars = {
            a = "\a",
            b = "\b",
            f = "\f",
            n = "\n",
            r = "\r",
            t = "\t",
            v = "\v"
        }
    };

    stream = false;

    tokens = {};

    openTag = false;
    definingAttribute = false;
    currentAttribute = false;

    line = 1;
    char = 1;
}

--[[
    @constructor
    @desc Constructs the Lexer instance by providing the instance with a 'stream'.
    @param <string - stream>
]]
function Lexer:__init__( stream, manual )
    if type( stream ) ~= "string" then
        return error "Failed to initialise lexer instance. Invalid stream paramater passed (expected string)"
    end
    self.stream = stream

    if not manual then
        self:formTokens()
    end
end

--[[
    @instance
    @desc This function is used to repeatedly call 'tokenize' until the stream has been completely consumed.
]]
function Lexer:formTokens()
    while self.stream and self.stream:find "%S" do
        self:tokenize()
    end
end

--[[
    @instance
    @desc A simple function that is used to add a token to the instances 'tokens' table.
    @param <table - token>
]]
function Lexer:pushToken( token )
    local tokens = self.tokens

    token.char = self.char
    token.line = self.line
    tokens[ #tokens + 1 ] = token
end

--[[
    @instance
    @desc Consumes the stream by 'amount'.
]]
function Lexer:consume( amount )
    local stream = self.stream
    self.stream = stream:sub( amount + 1 )

    self.char = self.char + amount
    return content
end

--[[
    @instance
    @desc Uses the Lua pattern provided to select text from the stream that matches the pattern. The text is then consumed from the stream (entire pattern, not just selected text)
    @param <string - pattern>, [number - offset]
]]
function Lexer:consumePattern( pattern, offset )
    local cnt = self.stream:match( pattern )

    self:consume( select( 2, self.stream:find( pattern ) ) + ( offset or 0 ) )
    return cnt
end

--[[
    @instance
    @desc Searches for the next occurence of 'opener'. Once found all text between the first two occurences is selected and consumed resulting in a XML_STRING token.
    @param <char - opener>
    @return <string - consumedString>
]]
function Lexer:consumeString( opener )
    local stream, closingIndex = self.stream

    if stream:find( opener, 2 ) then
        local str, c, escaped = {}
        for i = 2, #stream do
            c = stream:sub( i, i )

            if escaped then
                str[ #str + 1 ] = Lexer.escapeChars[ c ] or c
                escaped = false
            elseif c == "\\" then
                escaped = true
            elseif c == opener then
                self:consume( i )
                return table.concat( str )
            else
                str[ #str + 1 ] = c
            end
        end
    end

    self:throw( "Failed to lex stream. Expected string end ("..opener..")" )
end

--[[
    @instance
    @desc Converts the stream into tokens by way of pattern matching
]]
function Lexer:tokenize()
    self:trimStream()
    local stream, openTag, currentAttribute, definingAttribute = self.stream, self.openTag, self.currentAttribute, self.definingAttribute
    local first = stream:sub( 1, 1 )

    if stream:find "^<(%w+)" then
        self:pushToken({type = "XML_OPEN", value = self:consumePattern "^<(%w+)"})
        self.openTag = true
    elseif stream:find "^</(%w+)>" then
        self:pushToken({type = "XML_END", value = self:consumePattern "^</(%w+)>"})
        self.openTag = false
    elseif stream:find "^/>" then
        self:pushToken({type = "XML_END_CLOSE"})
        self:consume( 2 )
        self.openTag = false
    elseif openTag and stream:find "^%w+" then
        self:pushToken({type = definingAttribute and "XML_ATTRIBUTE_VALUE" or "XML_ATTRIBUTE", value = self:consumePattern "^%w+"})

        if not definingAttribute then
            self.currentAttribute = true
            return
        end
    elseif not openTag and stream:find "^([^<]+)" then
        local content = self:consumePattern "^([^<]+)"

        local newlines = select( 2, content:gsub("\n", "") )
        if newlines then self:newline( newlines ) end

        self:pushToken({type = "XML_CONTENT", value = content })
    elseif first == "=" then
        self:pushToken({type = "XML_ASSIGNMENT", value = "="})
        self:consume( 1 )

        if currentAttribute then
            self.definingAttribute = true
        end

        return
    elseif first == "'" or first == "\"" then
        self:pushToken({type = definingAttribute and "XML_STRING_ATTRIBUTE_VALUE" or "XML_STRING", value = self:consumeString( first )})
    elseif first == ">" then
        self:pushToken({type = "XML_CLOSE"})
        self.openTag = false
        self:consume( 1 )
    else
        self:throw("Unexpected block '"..stream:match("(.-)%s").."'")
    end

    if self.currentAttribute then self.currentAttribute = false end
    if self.definingAttribute then self.definingAttribute = false end
end

--[[
    @instance
    @desc Removes all trailing spaces from
]]
function Lexer:trimStream()
    -- Search for newlines
    local stream = self.stream

    local newLn = stream:match("^(\n+)")
    if newLn then self:newline( #newLn ) end

    local spaces = select( 2, stream:find "^%s*%S" )

    self.stream = stream:sub( spaces )
    self.char = self.char + spaces - 1
end

--[[
    @instance
    @desc Advanced 'line' by 'amount' (or 1) and sets 'char' back to zero
]]
function Lexer:newline( amount )
    self.line = self.line + ( amount or 1 )
    self.char = 0
end

--[[
    @instance
    @desc Throws error 'e' prefixed with information regarding current position and stores the error in 'exception' for later reference
]]
function Lexer:throw( e )
    self.exception = "Lexer Exception at line '"..self.line.."', char '"..self.char.."': "..e
    return error( self.exception )
end
